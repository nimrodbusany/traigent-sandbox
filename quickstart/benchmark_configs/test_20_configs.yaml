dataset:
  difficulty_distribution: null
  sampling_strategy: sequential
  total_examples: 10
execution:
  algorithm: grid
  early_stopping: false
  max_trials: 18
  mock_mode: true
  mode: local
name: test_20_configs
output:
  create_visualizations: true
  export_formats:
  - json
  - csv
  save_results: true
parameters:
  max_tokens:
    description: Maximum tokens in response
    enabled: true
    param_type: discrete
    values:
    - 10
    - 20
    - 50
  model:
    description: LLM model to use
    enabled: true
    param_type: categorical
    values:
    - gpt-3.5-turbo
    - gpt-4o-mini
  temperature:
    description: Sampling temperature (0.0 = deterministic, 1.0 = random)
    enabled: true
    param_type: continuous
    values:
    - 0.0
    - 0.3
    - 0.5
